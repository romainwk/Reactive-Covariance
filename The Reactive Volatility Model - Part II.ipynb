{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II - The Reactive Covariance Model - Paper 2\n",
    "In this section we derive from the leverage a new volatility measure, the reactive volatility introduced by Valeyre and al. in 2013. This measure allows to obtain a more efficient risk measure including the leverage effect and instantaneous price variations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'import_ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cb7886256ee6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mimport_ipynb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPortfolioOptimization\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# importer l'Excel de prix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'import_ipynb'"
     ]
    }
   ],
   "source": [
    "# Import relevant libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy as sp\n",
    "import numpy as np \n",
    "import math\n",
    "import datetime\n",
    "import time \n",
    "\n",
    "import import_ipynb\n",
    "import PortfolioOptimization as po\n",
    "# importer l'Excel de prix \n",
    "\n",
    "index_df     = pd.read_excel('Data\\indices.xls') \n",
    "index_df_out = index_df[len(index_df)-250:len(index_df)] # Out sample (calcul de la performance du portefeuille basé sur la matrice de variance covariance réactiv)\n",
    "index_df_out = index_df_out.reset_index(drop=True)\n",
    "index_df     = index_df[0:len(index_df)-250]             # In sample (estimation des matrices de variance covariance réactive)\n",
    "index_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Realized Volatility\n",
    "\n",
    "One basic approach for dynamically estimated the volatility is to consider the empirical estimator of the volatility over a rolling window:\n",
    "$$\n",
    "    \\hat{\\sigma}_{t,n} = \\dfrac{1}{n}\\sum\\limits_{i=1}^{n}(x_{t-i+1} - \\bar{x}_{t,n})^{2})\n",
    "$$\n",
    "where $\\bar{x}_{t,n} = \\dfrac{1}{n}\\sum\\limits_{i=1}^{n}x_{t-i+1}$ represents the mean over time window $[t-n, t]$.\n",
    "\n",
    "However such estimator is in pratice very poor since it does not reflect any instantaneous price variation (a strong innovation is mixed equally with minor ones) and the asymmetric relationship between asset returns and future volatility (leverage effect)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dictionnary = {0 : \"STOXX 600\", 1:\"STOXX 50\",2 : \"S&P 500\",3 : \"TOPIX\", 4: \"FTSE\", 5:\"DAX\", 6:\"NIKKEI\",7:\"NASDAQ\"}\n",
    "\n",
    "def computeRealizedVolatility(Ticker):\n",
    "    \n",
    "    n = len(index_df[Ticker])\n",
    "    annualized_vol = []\n",
    "    \n",
    "    # Step 1 : compute the returns \n",
    "    gross_returns = (index_df[Ticker]/index_df[Ticker].shift(1)).dropna()\n",
    "    \n",
    "    # Step 2 : compute the 250-d vol\n",
    "    for i in range(250,n):\n",
    "        annualized_vol.append(np.sqrt(np.cov(gross_returns[i-250:i],gross_returns[i-250:i])[0][1]) * np.sqrt(250)) # on commence a calculer a partir row 250\n",
    "    return annualized_vol\n",
    "\n",
    "Ticker = \"STOXX 600\" # changer ici pour avoir la vol réalisée du ticker souhaité \n",
    "\n",
    "dates = index_df[\"Date\"][250:len(index_df[\"Date\"])]\n",
    "dates = [pd.to_datetime(d) for d in dates]  # Conversion des dates dans le bon format\n",
    "                         \n",
    "volatility = {\"Date\" : dates, \"Volatility\" : computeRealizedVolatility(Ticker)} # Création d'un dictionnaire pour la vol\n",
    "volatility_df =pd.DataFrame(volatility)\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "volatility_df.plot(x= \"Date\", y='Volatility', figsize=(10, 8), grid=True)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Annualized Volatility')\n",
    "plt.title('Historical 250d Volatility')\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Reactive Volatility Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Reactive volatilty in the stock index case*__\n",
    "\n",
    "Let $I(t)$ be the stock index level at time $t$. Due to heteroskedasticity in asset returns, $\\frac{{\\Delta}{I(t+1)}}{I(t)}$, partly caused by price-volatility correlation, the authors define an estimator, $L(t)$, of the stock index, $I(t)$, such that the re-normalized arithmetic returns, $\\frac{{\\Delta}{I(t+1)}}{L(t)}$, become more homoscedastic. The later, is derived from two exponential weighted moving averages: the slow level, $L_s(t)$, and the fast level, $L_f(t)$, characterizing respectively the dynamic of the retarded and panic effect.\n",
    "\n",
    "\\begin{align}\n",
    "    \\textit{Slow level : }& L_s(t+1) = (1-\\lambda_{s})L_{s}(t)+\\lambda_{s}I(t+1) \\label{eq: slow level}\n",
    "    \\\\\n",
    "    \\textit{Fast level : }& L_f(t+1) = (1-\\lambda_{f})L_{f}(t)+\\lambda_{f}I(t+1) \\label{eq: fast level}\n",
    "\\end{align}\n",
    "\n",
    "where $\\lambda_s$ and $\\lambda_f$ represent decay rates of the leverage effect for specific and systematic risk. In order to make the estimator $L(t)$ more robust to outliers, the following filter function is applied to the slow and fast price level:\n",
    "\n",
    "\\begin{equation}\\label{eq: fonction filtre}\n",
    "    F_{\\phi}(z) = \\begin{cases}\n",
    "    \\dfrac{tanh(\\phi z)}{\\phi} & \\phi>0\\\\\n",
    "    \\hfil z & \\phi=0\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\phi$ represents the region of linearity of the function, i.e. the function is proportional to $z$ for small values of $\\lvert z\\rvert$ and converge toward a constant, $\\lvert\\frac{1}{\\phi}\\rvert$, for large values of $\\lvert z\\rvert$. The use of this filter assumes that the slow and fast price level cannot diverge more than $\\lvert\\frac{1}{\\phi}\\rvert$ from the current level of the price index. By restricting the price dynamics we then limit the impact of extreme events on the time series. \n",
    "\n",
    "Based on this filter, the new price level $L(t+1)$ at time $t+1$ is defined as the filtered slow level, $\\hat{L}_{s}(t+1)$, modulated by the panic effect measure, $\\hat{L}_f(t+1)$.\n",
    "\n",
    "\\begin{align}\n",
    "    \\textit{Slow level : } & \\hat{L}_{s}(t+1) = I(t+1)\\left((1+F_{\\phi}\\left(\\frac{L_{s}(t+1)}{I(t+1)}-1\\right)\\right) \\label{eq: filtered slow level}\n",
    "    \\\\\n",
    "    \\textit{Fast level : } & \\hat{L}_{f}(t+1)=1+F_{\\phi}\\left({\\left(\\frac{L_{f}(t+1)}{I(t+1)}\\right)}^{l}-1\\right) \\label{eq: filtered fast level}\n",
    "\\end{align}\n",
    "\t\\\\\n",
    "where $l = 8$ is the leverage parameter corresponding to the amplitude of the leverage effect between stock returns and volatility (Bouchaud and al., 2001). Finally, the new price level $L(t+1)$ is given by:\n",
    "\n",
    "\\begin{equation}\\label{eq: nouveaux prix}\n",
    "    L(t+1) = \\hat{L}_{s}(t+1)\\left(1+F_{\\phi}\\left({\\left(\\frac{L_{f}(t+1)}{I(t+1)}\\right)}^{l}-1\\right)\\right)\n",
    "\\end{equation} \n",
    "\n",
    "Derived from the re-normalized returns, $\\frac{{\\Delta}{I(t+1)}}{L(t)}$, a first approximation of the variance is obtained using an EWMA of parameter $\\lambda_{\\sigma} \\approx \\frac{1}{40} (economic uncertainty does not change significantly in a period of two months):\n",
    "\n",
    "\\begin{equation}\n",
    "    \\hat{\\sigma}_{I}^{2}(t+1)\n",
    "    =\n",
    "    (1-\\lambda_{\\sigma})\n",
    "    *\n",
    "    \\hat{\\sigma}_{I}^{2}(t)\n",
    "    +\n",
    "    \\lambda_{\\sigma}\n",
    "    *\n",
    "    \\left(\\frac{{\\Delta}{I(t+1)}}{L(t)}\\right)^{2}\n",
    "\\end{equation}\n",
    "\n",
    "In order to take into account instantaneous price variations the later is adjusted by the following reactive component $\\frac{L(t+1)}{I(t+1)}$:\n",
    "\t\n",
    "\\begin{equation}\\label{eq: volatilite reactive}\n",
    "    \\sigma_{I}(t+1)\n",
    "    =\n",
    "    \\hat{\\sigma}_{I}(t+1)\n",
    "    *\n",
    "    \\frac{L(t+1)}{I(t+1)}\n",
    "\\end{equation}\n",
    "\n",
    "__*Reactive volatilty in the individual stock case*__\n",
    "\n",
    "In the case of single stocks, the reactive volatility is obtained by replacing the index level $I(t)$ by the stock price $P_{i}(t)$ in the equation of the slow price level and the filtered slow price level:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\sigma_{i}(t+1)\n",
    "    =\n",
    "    \\hat{\\sigma}_{i}(t+1)\n",
    "    *\n",
    "    \\frac{L_{i}(t+1)}{P_{i}(t+1)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des niveaux du stock index tels que calibrés par Bouchaud & al.\n",
    "\n",
    "def compute_L_S(Ticker):\n",
    "    \n",
    "    lambda_S = 0.0241 # voir comment récupérer cette valeur depuis notre propre calibration\n",
    "    n = len(index_df[Ticker])\n",
    "    L_S = np.zeros(n)\n",
    "    for i in range(1,n):\n",
    "        L_S[i] = (1-lambda_S)*L_S[i-1] + lambda_S * index_df[Ticker][i]\n",
    "    return L_S\n",
    "\n",
    "def compute_L_F(Ticker):\n",
    "    lambda_F = 0.1484 # voir comment récupérer cette valeur depuis notre propre calibration\n",
    "    n = len(index_df[Ticker])\n",
    "    L_F = np.zeros(n)\n",
    "    for i in range(1,n):\n",
    "        L_F[i] = (1-lambda_F)*L_F[i-1] + lambda_F * index_df[Ticker][i]\n",
    "    return L_F\n",
    "\n",
    "def phi(z):\n",
    "    phi_parameter = 1/0.3\n",
    "    return ((z*phi_parameter)/phi_parameter)\n",
    "\n",
    "def compute_L_S_Hat(Ticker):\n",
    "    \n",
    "    n = len(index_df[Ticker])\n",
    "    L_S = compute_L_S(Ticker)\n",
    "    L_F = compute_L_F(Ticker)\n",
    "    L_S_Hat = np.zeros(n)\n",
    "    \n",
    "    for i in range(1,n):\n",
    "        L_S_Hat[i] = index_df[Ticker][i] * (1 + phi((L_S[i] - index_df[Ticker][i])/index_df[Ticker][i]))\n",
    "    return L_S_Hat    \n",
    "\n",
    "def compute_L(Ticker):\n",
    "    \n",
    "    n = len(index_df[Ticker])\n",
    "    L_S = compute_L_S(Ticker)\n",
    "    L_F = compute_L_F(Ticker)\n",
    "    L_S_Hat = compute_L_S_Hat(Ticker)\n",
    "    \n",
    "    L = np.zeros(n)\n",
    "    l = 8 ## Ce parametre provient du papier\n",
    "    \n",
    "    for i in range(1,n):\n",
    "        L[i] = L_S_Hat[i]*(1+l*(L_F[i] - index_df[Ticker][i])/L_F[i])\n",
    "    return L\n",
    "\n",
    "def renormalized_variance(Ticker):\n",
    "    n = len(index_df[Ticker])\n",
    "    lambda_sigma = 0.025 ## Ce parametre provient du papier \n",
    "    L = compute_L(Ticker)\n",
    "    \n",
    "    sigma_tild = np.zeros(n)\n",
    "    \n",
    "    for i in range(1,n):\n",
    "        sigma_tild[i] = (1-lambda_sigma)*sigma_tild[i-1] + lambda_sigma*(((index_df[Ticker][i]-index_df[Ticker][i-1])/L[i])**2)\n",
    "    return sigma_tild\n",
    "\n",
    "def reactive_volatility(Ticker):\n",
    "    \n",
    "    n = len(index_df[Ticker])\n",
    "    L_S = compute_L_S(Ticker)\n",
    "    L_F = compute_L_F(Ticker)\n",
    "    sigma_tild = renormalized_variance(Ticker)\n",
    "    sigma_reactive = np.zeros(n)\n",
    "    l = 8\n",
    "    \n",
    "    for i in range(1,n):\n",
    "        sigma_reactive[i] = sigma_tild[i] *(L_S[i]/index_df[Ticker][i])*(1+l*(L_F[i]-index_df[Ticker][i])/L_F[i])\n",
    "    return sigma_reactive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = index_df[\"Date\"][250:len(index_df[\"Date\"])]\n",
    "dates = [pd.to_datetime(d) for d in dates]  # Conversion des dates dans le bon format\n",
    "\n",
    "Ticker = \"STOXX 600\"\n",
    "\n",
    "reactive_vol = np.sqrt(reactive_volatility(Ticker)) * np.sqrt(250)  # Sans oublier d'annualiser + passer a la racine\n",
    "\n",
    "reactive_vol = reactive_vol[250:len(index_df[\"Date\"])]\n",
    "\n",
    "react_volatility_dict = {\"Date\" : dates, \"Reactive Volatility\" : reactive_vol} # Création d'un dictionnaire pour la vol\n",
    "react_volatility_df =pd.DataFrame(react_volatility_dict)\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "\n",
    "#react_volatility_df.plot(x= \"Date\", y=\"Reactive Volatility\", figsize=(10, 8), grid=True, color = \"darkred\")\n",
    "#react_volatility_df.plot(x= \"Date\", y='Historical Volatility', figsize=(10, 8), grid=True, color = \"slateblue\")\n",
    "\n",
    "x = dates\n",
    "y = reactive_vol\n",
    "y2 = computeRealizedVolatility(Ticker)\n",
    "\n",
    "plt.plot(x, y, color= \"darkred\")\n",
    "\n",
    "plt.plot(x, y2, color = \"slateblue\")\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Reactive Volatility')\n",
    "plt.title('Reactive Volatility')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - The Reactive covariance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the reactive volatility framework, one define the reactive covariance as :\n",
    "\n",
    "\\begin{equation}\\label{eq: covariance reactive}\n",
    "    \\Sigma_{t+1}^{i,j} = \\tilde{\\Sigma}^{i,j}_{t+1}\\dfrac{L_{t+1}^{i}}{P_{t+1}^{i}}\\dfrac{L_{t+1}^{j}}{P_{t+1}^{j}}\n",
    "\\end{equation}\n",
    "where\n",
    "\\begin{equation*}\n",
    "    \\tilde{\\Sigma}_{t+1}^{i,j} = (1-\\lambda_{\\sigma})\\tilde{\\Sigma}_{t}^{i,j} + \\lambda_{\\sigma}(\\dfrac{\\Delta P_{t}^{i}}{L_{t}^{i}}\\dfrac{\\Delta P_{t}^{j}}{L_{t}^{j}})\n",
    "\\end{equation*} and $L_{t+1}^{i}$ corresponds to the homoskedastic price level defined in the previous section.\n",
    "\n",
    "__Remarks:__\n",
    "    \n",
    "-  Considering $i=j$ we obtain the reactive volatility.\n",
    "-  Computing iteratively the previous relation gives :\n",
    "    \n",
    "    \\begin{equation}\\label{eq: covariance reactive developpee}\n",
    "        \\begin{cases}\n",
    "            \\Sigma_{t}^{i,j} = \\tilde{\\Sigma}_{t}^{i,j}\\dfrac{L_{t}^{i}}{P_{t}^{i}}\\dfrac{L_{t}^{j}}{P_{t}^{j}}\n",
    "            \\\\\t\t\t\n",
    "            \\tilde{\\Sigma}_{t}^{i,j} = \\lambda_{\\sigma}\\sum\\limits_{k=1}^{\\infty}(1-\\lambda_{\\sigma})^{k-1}\\dfrac{\\Delta P_{t-k}^{i}}{L_{t-k}^{i}}\\dfrac{\\Delta P_{t-k}^{j}}{L_{t-k}^{j}}\n",
    "        \\end{cases}\n",
    "    \\end{equation}\n",
    "\t\n",
    "    This relation shows two components: (i) a linear one, $\\tilde{\\Sigma}_{t}^{i,j}$, and (ii) a non-linear, $\\frac{L_{t}^{i}}{P_{t}^{i}}\\frac{L_{t}^{j}}{P_{t}^{j}}$. The long term dependency between returns is represented by the linear component while the short term relations are represented by the non linear component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_L_S(Ticker): # même définition que volatilité réactive\n",
    "    \n",
    "    lambda_S = 0.0241 # voir comment récupérer cette valeur depuis notre propre calibration\n",
    "    n = len(index_df[Ticker])\n",
    "    index = index_df[Ticker]\n",
    "    L_S = np.zeros(n)\n",
    "    for i in range(1,n):\n",
    "        L_S[i] = (1-lambda_S)*L_S[i-1] + lambda_S * index[i]\n",
    "    return L_S\n",
    "\n",
    "def compute_L_F(Ticker): # même définition que volatilité réactive\n",
    "    lambda_F = 0.1484 # voir comment récupérer cette valeur depuis notre propre calibration\n",
    "    n = len(index_df[Ticker])\n",
    "    index = index_df[Ticker]\n",
    "    L_F = np.zeros(n)\n",
    "    for i in range(1,n):\n",
    "        L_F[i] = (1-lambda_F)*L_F[i-1] + lambda_F * index[i]\n",
    "    return L_F\n",
    "\n",
    "def phi(z):\n",
    "    phi_parameter = 1/0.3\n",
    "    return ((z*phi_parameter)/phi_parameter)\n",
    "\n",
    "def compute_L_S_Hat(Ticker): # même définition que volatilité réactive\n",
    "    \n",
    "    n = len(index_df[Ticker])\n",
    "    L_S = compute_L_S(Ticker)\n",
    "    L_F = compute_L_F(Ticker)\n",
    "    L_S_Hat = np.zeros(n)\n",
    "    index = index_df[Ticker]\n",
    "    for i in range(1,n):\n",
    "        L_S_Hat[i] = index[i] * (1 + phi((L_S[i] - index[i])/index[i]))\n",
    "    return L_S_Hat    \n",
    "\n",
    "def compute_L(Ticker): # même définition que volatilité réactive\n",
    "    \n",
    "    n = len(index_df[Ticker])\n",
    "    L_S = compute_L_S(Ticker)\n",
    "    L_F = compute_L_F(Ticker)\n",
    "    L_S_Hat = compute_L_S_Hat(Ticker)\n",
    "    index = index_df[Ticker]\n",
    "    L = np.zeros(n)\n",
    "    l = 8 ## Ce parametre provient du papier\n",
    "    \n",
    "    for i in range(1,n):\n",
    "        L[i] = L_S_Hat[i]*(1+l*(L_F[i] - index[i])/L_F[i])\n",
    "    return L\n",
    "\n",
    "def renormalized_covariance(Ticker1,Ticker2):\n",
    "    n = len(index_df[Ticker1])\n",
    "    lambda_sigma = 0.025 ## Ce parametre provient du papier \n",
    "    L_i = compute_L(Ticker1)\n",
    "    L_j = compute_L(Ticker2)\n",
    "    index1 = index_df[Ticker1]\n",
    "    index2 = index_df[Ticker2]\n",
    "    sigma_tild = np.zeros(n)\n",
    "    \n",
    "    for t in range(1,n):\n",
    "        sigma_tild[t] = (1-lambda_sigma)*sigma_tild[t-1] + lambda_sigma*((index1[t]-index1[t-1])*(index2[t]- index2[t-1])/(L_i[t]*L_j[t]))\n",
    "    return sigma_tild\n",
    "\n",
    "def reactive_covariance(Ticker1,Ticker2):\n",
    "    \n",
    "    n = len(index_df[Ticker1])\n",
    "    L_i = compute_L(Ticker1)\n",
    "    L_j = compute_L(Ticker2)\n",
    "    index1 = index_df[Ticker1]\n",
    "    index2 = index_df[Ticker2]\n",
    "    sigma_tild = renormalized_covariance(Ticker1,Ticker2)\n",
    "    sigma_reactive = np.zeros(n)\n",
    "    l = 8\n",
    "    \n",
    "    for t in range(1,n):\n",
    "        sigma_reactive[t] = sigma_tild[t] *(L_i[t]*L_j[t])/(index1[t]*index2[t])\n",
    "    return sigma_reactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "def reactiveCovarianceMatrix(index_dictionnary):\n",
    "    n = len(index_dictionnary) # Regarde la taille du dictionnaire\n",
    "    t = len(index_df[index_dictionnary.get(0)]) ## on défini la dimension temporelle par rapport a la longueur du premier set de donnees \n",
    "    covariance = np.zeros((n,n,t)) # Création d'une matrice vide de taille n*n*t pour stocker les valeurs de covariances réactives dans le temps\n",
    "    \n",
    "    init = 0 # initialisation du j pour le calcul de la matrice de variance covariance \n",
    "    for i in range(0,n):\n",
    "        for j in range(init,n):\n",
    "            Xi = index_dictionnary.get(i)  # Recupere le nom de la colonne Xi\n",
    "            Xj = index_dictionnary.get(j)  # Recupere le nom de la colonne Xj\n",
    "            covariance[i][j] = reactive_covariance(Xi,Xj) ## Calcule la covariance réactive \n",
    "            \n",
    "        if (init >=1):\n",
    "            k = 1\n",
    "            for j in range(init-1,0,-1):\n",
    "                covariance[i][j] = covariance[i-k][j+k]\n",
    "                k = k + 1\n",
    "        init = init +1 # on incrémente le point de départ de j pour prendre en compte la symmétrie de la matrice\n",
    "            \n",
    "    return covariance\n",
    "\n",
    "rcov = reactiveCovarianceMatrix(index_dictionnary)\n",
    "#print(rcov)\n",
    "\n",
    "end = time.time()  # Pour timer le tout \n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sqrt(252.0*rcov[0,0,250:len(rcov[0,0,:])]))\n",
    "print(rcov[:,:,len(rcov[0,0,:])-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the achievable portfolio\n",
    "PortType  = {'MDP':[0.0, 0.0, 0.0], 'ERC':[1.0, 1.0, 0.0], 'GMV':[0.0, 0.0, 1.0]}\n",
    "# Optimization options (tolerance criterion, maximum iteration)\n",
    "optoption = [10^-15, 2000]\n",
    "# Define the reactive covariance matrix\n",
    "omega = rcov[:,:,len(rcov[0,0,:])-1]\n",
    "\n",
    "# Equal Risk Contribution Allocation\n",
    "werc = po.RiskBasedPortfolio(omega, PortType['ERC'], optoption)\n",
    "\n",
    "# Global Minimum Variance Allocation\n",
    "wgmv = po.RiskBasedPortfolio(omega, PortType['GMV'], optoption)\n",
    "\n",
    "#Plot weights allocation\n",
    "df   = pd.DataFrame({'ERC': 100*werc, 'GMV' : 100*wgmv}, index=range(len(omega[0])))\n",
    "ax   = df.plot.bar(rot=0)\n",
    "\n",
    "plt.title(\"Weights allocation\")\n",
    "plt.xlabel('Asset')\n",
    "plt.ylabel('Weights (in %)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PortfolioValue(w, index_dictionnary):\n",
    "    \n",
    "    nvar = len(index_dictionnary)                  # Recuperer la taille du dictionnaire\n",
    "    nobs = len(index_df_out[index_dictionnary[0]]) # Recuperer le nombre d'observation\n",
    "    ptfval = np.zeros((nobs,1))        # Preallocation d'une matrice de zeros de taille t*1 pour stocker la valuer du portefeuille\n",
    "\n",
    "    ptfval[0,0] = 100\n",
    "    ptfret = 0.0\n",
    "    for t in range(1,nobs):\n",
    "        for i in range(nvar):\n",
    "            ptfret += ((float(index_df_out[index_dictionnary[i]][t])/float(index_df_out[index_dictionnary[i]][t-1]))-1.0)*w[i]\n",
    "                               \n",
    "        ptfval[t,0] = ptfval[t-1,0]*(1+ptfret)\n",
    "        ptfret = 0.0\n",
    "    return ptfval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute portfolio value\n",
    "ptfercval = PortfolioValue(werc, index_dictionnary)\n",
    "ptfgmvval = PortfolioValue(wgmv, index_dictionnary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot portfolio value (out sample performance)\n",
    "plt.plot(ptfercval, label = 'ERC')\n",
    "plt.plot(ptfgmvval, label = 'GMV')\n",
    "plt.legend(loc='upper left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
